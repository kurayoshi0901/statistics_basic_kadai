{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-5IdvpcZf6J",
        "outputId": "3f373f69-c312-42ab-cfb5-94574512ecd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " y = x^2のx = 3での傾きは6.000001000927568です\n"
          ]
        }
      ],
      "source": [
        "#実践1:\n",
        "'''y=x^2のある値での傾き(微分)を求める計算式を定義してください。\n",
        "変化点を小さくすることで算出してください。'''\n",
        "def f(x):\n",
        "    return x**2\n",
        "\n",
        "def derivative(x, delta_x=1e-6):\n",
        "    return (f(x + delta_x) - f(x)) / delta_x\n",
        "\n",
        "x = 3\n",
        "slope = derivative(x)\n",
        "print(f\" y = x^2のx = {x}での傾きは約{slope}です\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kpWuMcDsvU46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 新しいセクション"
      ],
      "metadata": {
        "id": "mq9iiXiKfCV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#実践２\n",
        "'''任意の関数を受け取ってその関数の傾き(微分)を求める計算式を関数で定義してください。'''\n",
        "\n",
        "def derivative(func, delta_x=1e-6):\n",
        "    return (func(x + delta_x) - func(x)) / delta_x\n"
      ],
      "metadata": {
        "id": "R4A_2Dz2eBnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#実践3-1:行列演算\n",
        "'''以下の演算を実施してください。\n",
        "ベクトル同士の足し算・引き算\n",
        "(a) 足し算: u = (2, -3, 5),\n",
        "v = (-1, 4, 1)\n",
        "u + vを計算せよ。'''\n",
        "\n",
        "import numpy as np\n",
        "u = np.array([2, -3, 5]),\n",
        "v = np.array([-1, 4, 1])\n",
        "print(\"ベクトル同士の足し算・引き算\")\n",
        "print(f\"(a){u+v}\")\n",
        "\n",
        "'''(b) 引き算:\n",
        "x = (7, -2, 4),\n",
        "y = (3, 5, -1)\n",
        "x - yを計算せよ。'''\n",
        "\n",
        "x = np.array([7, -2, 4]),\n",
        "y = np.array([3, 5, -1])\n",
        "print(f\"(b){x-y}\")\n",
        "\n",
        "'''行列同士の足し算引き算'''\n",
        "'''(a)'''\n",
        "A = np.array([[1,2,0], [3,-1,4]])\n",
        "B = np.array([[4,1,2],[-2,3,1]])\n",
        "\n",
        "print(\"行列同士の足し算引き算\")\n",
        "print(f\"(a){A+B}\")\n",
        "\n",
        "'''(b) '''\n",
        "C = np.array([[5,7,2],[-3,4,6],[1,-2,3]])\n",
        "D = np.array([[2,-1,4],[6,3,-2],[-4,1,5]])\n",
        "print(f\"(b){C-D}\")\n",
        "\n",
        "'''ベクトルのスカラー倍\n",
        "u = (2, -5, 3)\n",
        "2uを計算せよ。'''\n",
        "\n",
        "u = (2, -5, 3)\n",
        "print(\"ベクトルのスカラー倍\")\n",
        "print(f\"2u={u *2}\")\n",
        "\n",
        "\n",
        "\n",
        "'''行列のスカラー倍\n",
        "-3Aを計算せよ。'''\n",
        "\n",
        "A2 = np.array([[1,4,2], [3,-2,5]])\n",
        "\n",
        "print(\"行列のスカラー倍\")\n",
        "print(f\"-3A = {-3*A2}\")\n",
        "\n",
        "'''ABを計算せよ。'''\n",
        "\n",
        "A3 = np.array([[2,1], [3,4], [5,2]])\n",
        "B3 = np.array([[6,2], [2,7]])\n",
        "\n",
        "print(f\"AB = {np.dot(A3, B3)}\")\n",
        "\n",
        "'''行列とベクトルの掛け算\n",
        "\n",
        "Auを計算せよ。'''\n",
        "\n",
        "A4= np.array([[1,2,3], [4,5,6]])\n",
        "u = np.array([2,3,1])\n",
        "\n",
        "print(\"行列とベクトルの掛け算\")\n",
        "print(f\"Au = {np.dot(A4,u)}\")\n",
        "\n",
        "'''行列と単位行列の掛け算\n",
        "AI3を計算せよ。(I3は3×3の単位行列)'''\n",
        "\n",
        "A5 = np.array([[2,3,1], [4,0,2], [5,6,7]])\n",
        "I = 1\n",
        "print(\"行列と単位行列の掛け算\")\n",
        "print(f\"AI3 = {A5*I}\")"
      ],
      "metadata": {
        "id": "yNrIwF70eB5n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "346d986a-d8c9-44c2-f7ba-e92a374394e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ベクトル同士の足し算・引き算\n",
            "(a)[[1 1 6]]\n",
            "(b)[[ 4 -7  5]]\n",
            "行列同士の足し算引き算\n",
            "(a)[[5 3 2]\n",
            " [1 2 5]]\n",
            "(b)[[ 3  8 -2]\n",
            " [-9  1  8]\n",
            " [ 5 -3 -2]]\n",
            "ベクトルのスカラー倍\n",
            "2u=(2, -5, 3, 2, -5, 3)\n",
            "行列のスカラー倍\n",
            "-3A = [[ -3 -12  -6]\n",
            " [ -9   6 -15]]\n",
            "AB = [[14 11]\n",
            " [26 34]\n",
            " [34 24]]\n",
            "行列とベクトルの掛け算\n",
            "Au = [11 29]\n",
            "行列と単位行列の掛け算\n",
            "AI3 = [[2 3 1]\n",
            " [4 0 2]\n",
            " [5 6 7]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#実践4-1(統計)\n",
        "'''サンプルデータ 生徒10人の数学とプログラミングの試験点数が以下のように与えられています。\n",
        "数学: [75, 82, 91, 64, 88, 73, 95, 67, 81, 70]\n",
        "プログラミング: [85, 76, 92, 68, 79, 81, 88, 65, 73, 87]\n",
        "問題1: 平均値を求める 数学とプログラミングの試験点数それぞれの平均点を求めてください。'''\n",
        "\n",
        "from math import sqrt\n",
        "\n",
        "math_scores = [75, 82, 91, 64, 88, 73, 95, 67, 81, 70]\n",
        "prog_scores = [85, 76, 92, 68, 79, 81, 88, 65, 73, 87]\n",
        "\n",
        "def mean(scores):\n",
        "    return sum(scores)/len(scores)\n",
        "\n",
        "math_mean = mean(math_scores)\n",
        "prog_mean = mean(prog_scores)\n",
        "print(f\"数学の平均点: {math_mean}\")\n",
        "print(f\"プログラミングの平均点: {prog_mean}\")\n",
        "\n",
        "# 問題2: 中央値\n",
        "def median(scores):\n",
        "    sorted_scores = sorted(scores)\n",
        "    n = len(sorted_scores)\n",
        "    if n % 2 == 1:\n",
        "        return sorted_scores[n // 2]\n",
        "    else:\n",
        "        right = n // 2\n",
        "        left = right - 1\n",
        "        return (sorted_scores[left] + sorted_scores[right]) / 2\n",
        "\n",
        "math_median = median(math_scores)\n",
        "prog_median = median(prog_scores)\n",
        "print(f\"数学の中央値: {math_median}\")\n",
        "print(f\"プログラミングの中央値: {prog_median}\")\n",
        "\n",
        "# 問題3: 最頻値\n",
        "def mode(scores):\n",
        "    count = {}\n",
        "    for score in scores:\n",
        "        count[score] = count.get(score, 0) + 1\n",
        "\n",
        "    max_count = max(count.values())\n",
        "    max_score = []\n",
        "    for key, value in count.items():\n",
        "         if value == max_count:\n",
        "            max_score.append(key)\n",
        "    if len(max_score) == len(count):\n",
        "        return list(count.keys())\n",
        "    elif len(max_score) == 1:\n",
        "        return max_score[0]\n",
        "\n",
        "math_mode = mode(math_scores)\n",
        "prog_mode = mode(prog_scores)\n",
        "print(f\"数学の最頻値: {math_mode}\")\n",
        "print(f\"プログラミングの最頻値: {prog_mode}\")\n",
        "\n",
        "\n",
        "# 問題4: 標準偏差と分散\n",
        "def stdev(scores):\n",
        "    mean_val = mean(scores)\n",
        "    import math\n",
        "    variance = sum((x - mean_val) ** 2 for x in scores) / len(scores)\n",
        "    return math.sqrt(variance)\n",
        "\n",
        "def variance(scores):\n",
        "    mean_val = mean(scores)\n",
        "    return sum((score - mean_val) ** 2 for score in scores) / len(scores)\n",
        "\n",
        "\n",
        "math_std = stdev(math_scores)\n",
        "prog_std = stdev(prog_scores)\n",
        "math_var = variance(math_scores)\n",
        "prog_var = variance(prog_scores)\n",
        "print(f\"数学の標準偏差: {math_std}\")\n",
        "print(f\"プログラミングの標準偏差: {prog_std}\")\n",
        "print(f\"数学の分散: {math_var}\")\n",
        "print(f\"プログラミングの分散: {prog_var}\")\n",
        "\n",
        "\n",
        "# 問題5: 相関係数(応用: 数式を確認する必要がある)\n",
        "def covariance(x, y):\n",
        "    x_mean = mean(x)\n",
        "    y_mean = mean(y)\n",
        "    cov = sum((x_i - x_mean) * (y_i - y_mean) for x_i, y_i in zip(x, y))\n",
        "    return cov / (len(x) - 1)\n",
        "\n",
        "def corr_coef(x, y):\n",
        "    return covariance(x, y)/(stdev(x)*stdev(y))\n",
        "\n",
        "corr = corr_coef(math_scores, prog_scores)\n",
        "print(f\"数学とプログラミングの相関係数: {corr}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6kezBvWNvVT",
        "outputId": "f93e43da-09ff-45b8-ef26-daa6bde2d1ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "数学の平均点: 78.6\n",
            "プログラミングの平均点: 79.4\n",
            "数学の中央値: 78.0\n",
            "プログラミングの中央値: 80.0\n",
            "数学の最頻値: [75, 82, 91, 64, 88, 73, 95, 67, 81, 70]\n",
            "プログラミングの最頻値: [85, 76, 92, 68, 79, 81, 88, 65, 73, 87]\n",
            "数学の標準偏差: 9.971960689854328\n",
            "プログラミングの標準偏差: 8.452218643646175\n",
            "数学の分散: 99.44\n",
            "プログラミングの分散: 71.44\n",
            "数学とプログラミングの相関係数: 0.6665201372516742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "実践4-2\n",
        "標準正規分布について調べて報告してください。正規分布との違いは何ですか？\n",
        "\n",
        "\n",
        "標準正規分布は、平均が0で標準偏差が1の正規分布を指します。正規分布と標準正規分布の主な違いは、平均と標準偏差の値です。"
      ],
      "metadata": {
        "id": "0lBXnbZE-9EP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "実践4-3(応用):\n",
        "二項分布・ポアソン分布・指数分布・ベルヌーイ分布・幾何分布について調べて報告してください。\n",
        "\n",
        "二項分布 (Binomial Distribution):\n",
        "二項分布は、2つの結果のうち1つを成功として定義し、それぞれの成功確率が同じである独立なベルヌーイ試行をn回行った場合の成功回数の確率分布です。\n",
        "\n",
        "ポアソン分布 (Poisson Distribution):\n",
        "ポアソン分布は、ある一定の時間や領域で発生するイベントの回数が、平均的に一定の率で起こるときに、その回数の確率分布を表します。\n",
        "例：単位時間あたりの交通事故の発生数など\n",
        "\n",
        "指数分布 (Exponential Distribution):\n",
        "指数分布は、ある事象が起こるまでの時間間隔が従う確率分布です。\n",
        "例：あるイベントが発生するまでの待ち時間や製品の寿命など\n",
        "\n",
        "ベルヌーイ分布 (Bernoulli Distribution):\n",
        "ベルヌーイ分布は、2つの結果（例えば成功と失敗）を持つ試行の確率分布です。\n",
        "例:コインを5回投げた時に表2回出る確率\n",
        "\n",
        "幾何分布 (Geometric Distribution):\n",
        "幾何分布は、ベルヌーイ試行で初めて成功が起こるまでの失敗の回数（試行回数）の確率分布です。\n",
        "例:1の目が出るまでにサイコロを振り続ける回数の分布\n",
        "\n"
      ],
      "metadata": {
        "id": "l-4-vn2d_Oix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "実践5-1(回帰)\n",
        "最小二乗法について説明してください。\n",
        "\n",
        "最小二乗法は、「予測モデルによる予測値」と「実測値」の誤差を2乗した和を最小化する手法です。誤差の2乗の和を最小化するような予測モデルのパラメータを特定し、予測モデルを実測値にフィットさせます"
      ],
      "metadata": {
        "id": "Jy0KbBzpAll7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "実践5-2:\n",
        "過学習について説明してください。 過学習が起きると何が問題でしょうか。\n",
        "\n",
        "過学習（Overfitting）は、機械学習や統計モデリングにおいて、モデルが訓練データに過度に適合しすぎる現象を指します。\n",
        "\n",
        "過学習が起きると、モデルが訓練データに対して過度に適合するため、新しいデータに対してうまく予測できなくなります。つまり、モデルが訓練データに適合しすぎてしまうため、本来の目的である未知のデータに対する予測能力が低下します。\n"
      ],
      "metadata": {
        "id": "jYMaRnuLBKk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#実践5-4:\n",
        "'''以下の決定係数の算出問題を計算してください。\n",
        "\n",
        "データセット\n",
        "\n",
        "x (年収/万円): 300, 400, 500, 600, 700\n",
        "\n",
        "y (支出額/万円): 150, 220, 300, 380, 420\n",
        "\n",
        "以下のサンプルコードを埋めてください。'''\n",
        "\n",
        "\n",
        "import math\n",
        "\n",
        "# データ\n",
        "x = [300, 400, 500, 600, 700]\n",
        "y = [150, 220, 300, 380, 420]\n",
        "n = len(x)\n",
        "\n",
        "# 平均値\n",
        "x_mean = sum(x) / n\n",
        "y_mean = sum(y) / n\n",
        "\n",
        "# 直線の係数 a, b (最小二乗法)\n",
        "numer = sum((x_i - x_mean) * (y_i - y_mean) for x_i, y_i in zip(x, y))\n",
        "denom = sum((x_i - x_mean) ** 2 for x_i in x)\n",
        "a = numer / denom\n",
        "b = y_mean - a * x_mean\n",
        "\n",
        "# 予測値\n",
        "y_pred = [a * x_i + b for x_i in x]\n",
        "\n",
        "# 決定係数\n",
        "ss_res = sum((y_i - y_pred_i) for y_i, y_pred_i in zip(y, y_pred)) ** 2\n",
        "ss_tot = sum((y_i - y_mean) ** 2 for y_i in y)\n",
        "r_squared = 1 - (ss_res / ss_tot)\n",
        "\n",
        "print(f\"直線の係数: a = {a}, b = {b}\")\n",
        "print(f\"決定係数 R^2 = {r_squared}\")"
      ],
      "metadata": {
        "id": "J2CfQKn1-7XV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e86f3abc-302a-452c-d4f9-6ba2db99c58c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "直線の係数: a = 0.7, b = -56.0\n",
            "決定係数 R^2 = 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#実践5-5\n",
        "'''単回帰と重回帰の違いを数式を例にして説明してください。'''\n",
        "\n",
        "単回帰は、1つの要素()から数値を予測するモデルであること\n",
        "　y=ax+b\n",
        "\n",
        "・重回帰は、複数の要素から数値を予測するモデルであること\n",
        "y=a1x1+a2x2​+⋯+anxn+b"
      ],
      "metadata": {
        "id": "VA4_h0TZ0HId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#実践5-6\n",
        "'''リッジ回帰・ラッソ回帰・elastic-netの違いについて調べて報告してください。\n",
        "例えば説明変数の数が多い場合はどの手法を使うべきでしょうか？'''\n",
        "\n",
        "Ridge回帰は重みの2乗和に制約を課しています。これによって影響度の少ない要素の重みを抑え、過学習を抑制します。\n",
        "LASSO回帰は、重みの絶対値の和に制約を課します。一部の特徴量のみが重要なとき、Lasso回帰を、\n",
        "全ての特徴量が重要だが、過学習を防ぎたいときはRidge回帰を使用する良いらしい。\n",
        "elastic-netは両方のいい所を合わせたもの。\n",
        "\n"
      ],
      "metadata": {
        "id": "R-G1xAGC30Kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 実践6-1(分類: 混同行列/評価指標の定義)\n",
        "'''以下の実際のラベル値と予測値が与えられています。混同行列、Recall、Precision、F値をそれぞれ計算してください。ライブラリは使わず手計算で行ってその結果を記載してください。\n",
        "\n",
        "補足) Recall=再現率, Precision=適合率\n",
        "\n",
        "実際のラベル値: [1, 0, 1, 1, 0, 1, 0, 1, 0, 0]\n",
        "\n",
        "予測値: [1, 1, 0, 1, 0, 0, 1, 1, 0, 0]'''\n",
        "\n",
        "Rcall:0.4\n",
        "Precision:0.6\n",
        "F値:0.48"
      ],
      "metadata": {
        "id": "qIMMy7o5HhaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#実践6-2 (応用)\n",
        "'''不純度はGini不純度とエントロピーが代表的です。\n",
        "エントロピーについて概要を調べてみてください。'''\n",
        "\n",
        "エントロピーは、データの不確実性や混乱度を測定するための重要な指標で、\n",
        "エントロピーを最小化するようにデータを分割することで、より純度の高いノードを作成できます。\n",
        "決定木は過学習しやすいモデルです。ジニ不純度とエントロピーを使用して適切な分割を行うことで、\n",
        "過度に複雑なツリー構造を避け、より一般化されたモデルを構築できます。\n",
        "\n"
      ],
      "metadata": {
        "id": "FH6HysnlI5R5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#実践6-3\n",
        "'''木構造で過学習を防ぐ方法としてどんな方法がありますか？'''\n",
        "木構造の深さに上限を設ける\n",
        "木構造の葉（条件分岐の最も先の部分）の枚数に上限を設ける\n",
        "葉のデータ数に最小値を設ける"
      ],
      "metadata": {
        "id": "GWUr2nsnM9L-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#実践6-4(応用)\n",
        "'''上記説明でのGini不純度の計算をPythonを用いて計算してみてください。\n",
        "\n",
        "Gini不純度の計算方法を関数として定義して計算ください。'''\n",
        "\n",
        "def gini_impurity(pass_count: int, fail_count: int) -> float:\n",
        "    \"\"\"\n",
        "    Calculate the Gini impurity for a binary classification problem.\n",
        "\n",
        "    Args:\n",
        "        pass_count (int): The number of passing instances.\n",
        "        fail_count (int): The number of failing instances.\n",
        "\n",
        "    Returns:\n",
        "        float: The Gini impurity value.\n",
        "    \"\"\"\n",
        "    total_count = pass_count + fail_count\n",
        "    if total_count == 0:\n",
        "        return 0\n",
        "    p_pass = pass_count / total_count\n",
        "    p_fail = fail_count / total_count\n",
        "    return 1 - (p_pass ** 2 + p_fail ** 2)\n",
        "\n",
        "over_10h = gini_impurity (4,2)\n",
        "print(f\"10h以上の勉強での不純度＝{over_10h}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvj6v3hbOE0B",
        "outputId": "5a7659c4-6c68-40ed-b158-8446a30586a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10h以上の勉強での不純度＝0.4444444444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#実践7-1(クラスタリング): 応用\n",
        "'''調査問題1: クラスタリングアルゴリズムの種類と特徴'\n",
        "クラスタリングにはどのようなアルゴリズムがあるか調べてみましょう。代表的なアルゴリズムの種類、概要、利点・欠点をまとめてください'''\n",
        "\n",
        "クラスタリングの種類は、グルーピング方法の違いで「非階層的クラスタリング」と「階層的クラスタリング」に大別。\n",
        "・非階層的クラスタリング\n",
        "「非階層的クラスタリング」とは、階層を作らず、単にグループ分けをするクラスタリングのこと。\n",
        "母集団の中で近いデータをまとめ、事前に指定されたクラスタ数に分割。\n",
        "非階層的クラスタリングにはk-means法、混合正規分布の2つの方法がある\n",
        "\n",
        "・階層的クラスタリング\n",
        "階層的クラスタリングは、観測値同士がどのくらい似ているかを「距離」とした場合、距離の近さごとにクラスタをまとめていく手法。\n",
        "グループ化していく過程は「樹形図（デンドログラム：dendrogram）」で表現でき、可視化される点が特徴です。\n",
        "ウォード法, 群平均法, 最短（最長）距離法\n",
        "\n",
        "k-means\n",
        "最初に指定したクラスタの数だけ「重心」をランダムに指定し、その重心を基準にクラスタを分けていくという手法\n",
        "＜長所＞\n",
        "・階層型クラスター分析よりも計算量が少なく、サンプルサイズが比較的大きなデータを分類するのに適している\n",
        "＜短所＞\n",
        "・クラスタ数を事前に決める必要がある\n",
        "・重心の初期値によって結果が変わる\n",
        "・外れ値やノイズの影響を受けやすい\n",
        "\n",
        "ウォード法\n",
        "ウォード法は、それぞれのデータの平方和（それぞれのデータと平均値の差を二乗した値の和）を求め、\n",
        "平方和が小さなものからクラスタを作っていく手法。\n",
        "平方和はデータのばらつきを表す。\n",
        "＜長所＞\n",
        "バランスよくデータを分類することが可能で、階層クラスタリングの中ではよく使われる手法。\n",
        "分析したいデータに応じた計算方法を選ぶことが重要ですが、「迷ったらウォード法」と言われるほど、ウォード法はバラつきを抑えた分析が可能。\n",
        "＜短所＞\n",
        "計算量が多い\n",
        "\n",
        "群平均法\n",
        "群平均法では、2つのクラスタを構成するデータのすべての組み合わせの距離を求め、その平均をクラスタ間の距離とする手法\n",
        "＜長所＞\n",
        "クラスタ内に外れ値があったとしても影響を受けにくい\n",
        "ウォード法に比べると計算量が少ない\n",
        "＜短所＞\n",
        "ウォード法より精度が劣ることが多い\n",
        "\n",
        "最短距離法\n",
        "最短距離法は、2つのクラスタ間で一番近いデータ同士の距離を、クラスタ間の距離として採用する手法\n",
        "＜長所＞\n",
        "ウォード法に比べると計算量が少ない\n",
        "＜短所＞\n",
        "クラスタ内に外れ値があった場合、最短距離法では鎖効果が出やすくなり、分類感度が低くなってしまう\n",
        "\n",
        "最長距離法\n",
        "最長距離法は最短距離法とは逆の手法で、クラスタを構成する要素同士のすべての距離の中で最長のものを、クラスタ間の距離として採用。\n",
        "＜長所＞\n",
        "ウォード法に比べると計算量が少ない\n",
        "＜短所＞\n",
        "クラスタ内に外れ値があった場合、最短距離法では鎖効果が出やすくなり、分類感度が低くなってしまう\n",
        "\n",
        "'''調査問題2: 距離尺度の種類と使い分けクラスタリングでは、データ点間の類似性を測る尺度が必要です。\n",
        "様々な距離尺度があるので、代表的な距離尺度とその特徴、使い分けをまとめてください。'''\n",
        "\n",
        "距離尺度は、データの性質やクラスタリングの目的に応じて選択する必要がある\n",
        "ユークリッド距離 (Euclidean Distance)\n",
        "＜特徴＞\n",
        "二点間の直線距離を測定。\n",
        "\n",
        "マンハッタン距離 (Manhattan Distance)\n",
        "＜特徴＞\n",
        "データ点間の軸に沿った距離を測定\n",
        "\n",
        "コサイン類似度 (Cosine Similarity)\n",
        "＜特徴＞\n",
        "二つのベクトル間の角度の余弦値を測定。\n",
        "\n",
        "ジャッカード距離 (Jaccard Distance)\n",
        "＜特徴＞\n",
        "二つの集合間の非類似度を測定。集合の交わりの割合を考慮\n",
        "\n",
        "ハミング距離 (Hamming Distance)\n",
        "＜特徴＞\n",
        "二つの同じ長さの文字列間の異なる位置の個数を測定\n",
        "\n",
        "マハラノビス距離\n",
        "＜特徴＞\n",
        "データの分散共分散行列を考慮して距離を測定\n",
        "\n",
        "使い分け\n",
        "ユークリッド距離やマンハッタン距離は数値データに適しており、コサイン類似度はテキストデータや高次元スパースデータに有効。\n",
        "ジャッカード距離やハミング距離は質的データやバイナリデータに適す。\n",
        "マハラノビス距離は異なるスケールや相関を持つデータに対して有効。データの特性を理解し\n",
        "、適切な距離尺度を選ぶことで、効果的なクラスタリングが可能\n",
        "\n",
        "'''調査問題3: 質的データのクラスタリング\n",
        "これまでは数値データを扱いましたが、質的データ(カテゴリデータ)をクラスタリングする方法も考えられます。\n",
        "質的データをクラスタリングする際の工夫点や注意点を調べてみましょう。'''\n",
        "\n",
        "質的データのクラスタリングにおける工夫点・注意点\n",
        "1. 適切な距離尺度の選択\n",
        "質的データのクラスタリングでは、データの性質に適した距離尺度を選択することが重要。\n",
        "\n",
        "質的データでよく使用される距離尺度\n",
        "ジャッカード係数: 二つの集合間の類似度を測定し。バイナリデータやカテゴリカルデータに適す。\n",
        "ハミング距離: 二つの文字列間の異なる位置の個数を測定。バイナリデータに適す。\n",
        "\n",
        "2. データの前処理\n",
        "質的データをクラスタリングする前に、データの前処理が必要。\n",
        "\n",
        "エンコーディング: 質的データを数値データに変換する方法として、ワンホットエンコーディングやラベルエンコーディングがある。\n",
        "ワンホットエンコーディングは、カテゴリ間の距離を均等に保つために有効。\n",
        "\n",
        "3. クラスタ数の選定\n",
        "質的データのクラスタ数を選定する際には、以下の方法が有効。\n",
        "シルエットスコア: 各データポイントのクラスタリングの良さを評価します。\n",
        "エルボー法: クラスタ数に対するコスト関数の変化をグラフにプロットし、膝点（エルボー）を見つける方法です。\n",
        "\n",
        "'''調査問題4: クラスタリング評価指標\n",
        "クラスタリング結果の良し悪しを評価する指標があります。\n",
        "代表的な評価指標とその概要、利用シーンをまとめてください。'''\n",
        "\n",
        "シルエット係数\n",
        "シルエット係数は、各データポイントのクラスタリングの品質を評価する指標。\n",
        "スコアは -1 から 1 の範囲を取り、1 に近いほど良いクラスタリングを示す。\n",
        "＜利用シーン＞\n",
        "クラスタリングアルゴリズムのパフォーマンスを比較する際に使用。\n",
        "クラスタ数を決定する際の参考としても用いられる。\n",
        "\n",
        "ダビーズ・ボウルダイン基準\n",
        "クラスタのコンパクトさとクラスタ間の分離を評価する指標。\n",
        "＜利用シーン＞\n",
        "複数のクラスタリング結果を比較する際に使用。\n",
        "クラスタ数の決定にも役立つ。\n",
        "\n",
        "Calinski Harabasz基準\n",
        "WSSに対するクラスター間の分散（データセットの重心からすべてのクラスターの重心の分散）の割合\n",
        "＜利用シーン＞\n",
        "最適なクラスター数を評価\n",
        "\n",
        "Inertia\n",
        "クラスタ内のサンプルとクラスタ中心の距離の二乗和を表す指標\n",
        "＜利用シーン＞\n",
        "K-meansクラスタリングの最適なクラスタ数を決定する際に使用。\n",
        "エルボー法と組み合わせて、適切なクラスタ数を視覚的に確認。\n",
        "\n",
        "\n",
        "\n",
        "'''調査問題5: クラスタリングの実践的な利用例\n",
        "クラスタリングはどのような分野で利用されているか、実践的な利用例を調べてみましょう。\n",
        "マーケティング、画像処理、自然言語処理などの具体例を挙げてください。'''\n",
        "\n",
        "＜マーケティング＞\n",
        "顧客セグメンテーション\n",
        "顧客を異なるグループに分類し、それぞれのグループに対して\n",
        "最適なマーケティング戦略を立てるために利用されます。\n",
        "例\n",
        "ターゲットマーケティング: 顧客データ（購買履歴、行動パターン、デモグラフィック情報など）をクラスタリングし、\n",
        "特定の製品やキャンペーンに最適なターゲットグループを見つける。\n",
        "小売業、eコマース、金融サービスなど、顧客データを大量に持つ業界で広く利用されています。\n",
        "\n",
        "＜画像処理＞\n",
        "画像セグメンテーション\n",
        "画像を意味のある部分に分割し、異なるオブジェクトや領域を識別するために利用されます。\n",
        "\n",
        "例\n",
        "医用画像処理: MRIやCTスキャンの画像をクラスタリングし、腫瘍や異常部分を識別する。\n",
        "顔認識: 顔画像をクラスタリングして、異なる表情や照明条件に対応する。\n",
        "医療分野、監視システム、自動運転車など、精度の高い画像認識が必要な分野で活用されています。\n",
        "\n",
        "\n",
        "＜自然言語処理 (NLP)＞\n",
        "テキストクラスタリング\n",
        "文書やテキストデータをクラスタリングし、類似した内容のものをグループ化するために利用されます。\n",
        "例\n",
        "トピックモデリング: ニュース記事、論文、ソーシャルメディアの投稿などをクラスタリングし、異なるトピックに分類する。\n",
        "チャットボット: 類似した問い合わせをグループ化し、効率的な応答を生成する。\n",
        "利用シーン:\n",
        "情報検索、コンテンツフィルタリング、カスタマーサポートなど、テキストデータの整理と分析が重要な領域で使用されています。"
      ],
      "metadata": {
        "id": "Xvy6BPoxRhfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5viWZgJd-4mX"
      }
    }
  ]
}